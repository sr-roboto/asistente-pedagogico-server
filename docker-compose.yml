services:
  server:
    build: ./server
    ports:
      - "8000:8000"
    env_file:
      - ./server/.env
    environment:
      - HOST=0.0.0.0
      - OLLAMA_BASE_URL=http://ollama:11434
      - AI_PROVIDER=ollama # Options: ollama, gemini
    volumes:
      - ./server/faiss_index_ollama:/app/faiss_index_ollama
      - ./server/faiss_index_gemini:/app/faiss_index_gemini
      - ./server/data:/app/data
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

  client:
    build: ./client
    ports:
      - "80:80"
    depends_on:
      - server

volumes:
  ollama_data:
